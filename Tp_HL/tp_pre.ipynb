{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4580aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import trange\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48031781",
   "metadata": {},
   "source": [
    "# hl_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4231b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import convert_to_single_emb, graph_transform\n",
    "from trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bed2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checknodes(df, max_node=150):\n",
    "    index=[]\n",
    "    for i in range(len(df)):\n",
    "        smile = df['smiles'][i]\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        num_node = mol.GetNumAtoms()\n",
    "        if num_node>max_node:\n",
    "            pass\n",
    "        else:\n",
    "            index.append(i)\n",
    "    return df.loc[index]\n",
    "def get_inputs_bysmile(smi, max_node, shuffle_=False):\n",
    "    smile = smi\n",
    "    num_node, graph, adj = graph_transform(smile, max_node=max_node)\n",
    "    graph = convert_to_single_emb(graph).long()\n",
    "    mask = torch.zeros(max_node, 1)   \n",
    "\n",
    "    pad1 = nn.ConstantPad2d((0, 0, 0, max_node - num_node), 0)\n",
    "    pad2 = nn.ConstantPad2d((0, max_node - num_node, 0, max_node - num_node), 0)\n",
    "\n",
    "    padded_graph = pad1(graph)\n",
    "    padded_adj = pad2(adj)\n",
    "    mask[:num_node] = 1/num_node\n",
    "\n",
    "    # if shuffle_:\n",
    "    #    padded_graph, padded_adj, mask = shuffle(padded_graph, padded_adj, mask, self.max_node)\n",
    "\n",
    "    assert padded_adj.shape[0] == max_node\n",
    "    assert padded_graph.shape[0] == max_node\n",
    "\n",
    "    return smile, padded_graph, padded_adj, mask\n",
    "\n",
    "def batch_get_inputs_bysmile(smi_list, max_node, shuffle_=False):\n",
    "    batch_size = len(smi_list)\n",
    "    graphs = None\n",
    "    for i in range(len(smi_list)):\n",
    "        smi = smi_list[i]\n",
    "        smile, padded_graph, padded_adj, mask = get_inputs_bysmile(smi, max_node=max_node)\n",
    "        if graphs is None:\n",
    "            graphs = torch.zeros(batch_size, max_node, padded_graph.shape[-1]).long()\n",
    "            adjs = torch.zeros(batch_size, max_node, max_node)\n",
    "            masks = torch.zeros(batch_size, max_node, 1)\n",
    "        graphs[i, :, :] = padded_graph\n",
    "        adjs[i, :, :] = padded_adj\n",
    "        masks[i, :, :] = mask\n",
    "    return graphs, adjs, masks\n",
    "\n",
    "def hl_pre_single(smiles, max_node, mean, std):\n",
    "    graphs, adjs, masks = batch_get_inputs_bysmile([smiles], max_node=max_node)\n",
    "    graphs = graphs.to(device)\n",
    "    adjs = adjs.to(device)\n",
    "    masks = masks.to(device)\n",
    "    with torch.no_grad():\n",
    "        results1 = hl_model([graphs, adjs, masks])\n",
    "    results1 = torch.add(torch.multiply(results1, std), mean)\n",
    "    return results1[0].numpy()\n",
    "\n",
    "def hl_pre_batch(smiles_list, max_node, mean, std):\n",
    "    graphs, adjs, masks = batch_get_inputs_bysmile(smiles_list, max_node=max_node)\n",
    "    graphs = graphs.to(device)\n",
    "    adjs = adjs.to(device)\n",
    "    masks = masks.to(device)\n",
    "    with torch.no_grad():\n",
    "        results1 = hl_model([graphs, adjs, masks])\n",
    "    results1 = torch.add(torch.multiply(results1, std), mean)\n",
    "    return results1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03425940",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "hl_model = torch.load('HL_GENEncoderPre.pt').to(device)\n",
    "# 若出现兼容性问题：1.10版本的gelu并无该属性，提前定义\n",
    "for m in hl_model.modules():\n",
    "    if type(m) is nn.GELU:\n",
    "        m.approximate = 'none'\n",
    "\n",
    "hl_model.eval()\n",
    "mean = hl_model.scaler[0].to(device)\n",
    "std = hl_model.scaler[1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22842568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.4206886, -3.2992914,  3.1222663], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_pre_single('N#CC1=CC=C(C=C1C#N)OC2=CC(OB(OC3=CC(OC4=CC(C#N)=C(C=C4)C#N)=CC=C3)OC5=CC=CC(OC6=CC=C(C#N)C(C#N)=C6)=C5)=CC=C2', hl_model.max_node, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0aca8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.393021 , -1.2908527,  5.1026797], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_pre_single('c1ccccc1', hl_model.max_node, mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd76ae4",
   "metadata": {},
   "source": [
    "# tp_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5316efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a8f25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate descriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from rdkit.Chem import Descriptors\n",
    "from mordred import Calculator, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ffe50c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smi2smi(smiles, chiral=True, H=False):\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    smi = Chem.MolToSmiles(m, isomericSmiles=chiral, allHsExplicit=H)\n",
    "    return smi    \n",
    "\n",
    "def calculate_des(smiles_list, des_cal):\n",
    "    smiles_ = [smi2smi(smiles) for smiles in smiles_list]\n",
    "    mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_]\n",
    "    des_list = []\n",
    "    for mol in mols:\n",
    "        des_ = []\n",
    "        for key in des_cal.keys():\n",
    "            try:\n",
    "                tmp = des_cal[key](mol)\n",
    "            except:\n",
    "                tmp = np.nan\n",
    "            des_.append(tmp)\n",
    "        des_list.append(des_)\n",
    "    return np.array(des_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "953328e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_mw(PN_smiles, ini_smiles, dsc_rate, PN_descriptors_mord, ini_descriptors_mord, mw=None):\n",
    "    if mw is None:\n",
    "        mw = Chem.Descriptors.ExactMolWt(Chem.MolFromSmiles(smiles))\n",
    "    hls_1 = hl_pre_single(PN_smiles, hl_model.max_node, mean, std)\n",
    "    hls_2 = hl_pre_single(ini_smiles, hl_model.max_node, mean, std)\n",
    "    PN_pre_homo = np.array([hls_1[0]])\n",
    "    ini_pre_hl = np.array([hls_2[-1]])\n",
    "    \n",
    "    PN_des = calculate_des([PN_smiles], PN_descriptors_mord)[0]\n",
    "    ini_des = calculate_des([ini_smiles], ini_descriptors_mord)[0]\n",
    "    \n",
    "    inputs = np.concatenate((PN_des, ini_des, np.array([dsc_rate]),np.array([mw]), PN_pre_homo, ini_pre_hl))\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def get_input(PN_smiles, ini_smiles, dsc_rate, PN_descriptors_mord, ini_descriptors_mord):\n",
    "    hls_1 = hl_pre_single(PN_smiles, hl_model.max_node, mean, std)\n",
    "    hls_2 = hl_pre_single(ini_smiles, hl_model.max_node, mean, std)\n",
    "    PN_pre_homo = np.array([hls_1[0]])\n",
    "    ini_pre_hl = np.array([hls_2[-1]])\n",
    "    \n",
    "    PN_des = calculate_des([PN_smiles], PN_descriptors_mord)[0]\n",
    "    ini_des = calculate_des([ini_smiles], ini_descriptors_mord)[0]\n",
    "    \n",
    "    inputs = np.concatenate((PN_des, ini_des, np.array([dsc_rate]), PN_pre_homo, ini_pre_hl))\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def get_input_batch(PN_smiles_list, ini_smiles_list, dsc_rate, PN_descriptors_mord, ini_descriptors_mord):\n",
    "    hls_1 = hl_pre_batch(PN_smiles_list, hl_model.max_node, mean, std)\n",
    "    hls_2 = hl_pre_batch(ini_smiles_list, hl_model.max_node, mean, std)\n",
    "    PN_pre_homo = hls_1[:,0].reshape(-1,1)\n",
    "    ini_pre_hl = hls_2[:,-1].reshape(-1,1)\n",
    "    \n",
    "    PN_des = calculate_des(PN_smiles_list, PN_descriptors_mord)\n",
    "    ini_des = calculate_des(ini_smiles_list, ini_descriptors_mord)\n",
    "    inputs = np.concatenate((PN_des, ini_des, np.array([dsc_rate] * len(PN_smiles_list)).reshape(-1,1), PN_pre_homo, ini_pre_hl), axis=1)\n",
    "    \n",
    "    return inputs    \n",
    "\n",
    "def tp_pre(model, inputs):\n",
    "    [x_mean, x_std] = model.x_scaler\n",
    "    [y_mean, y_std] = model.y_scaler\n",
    "    inputs_ = (inputs.reshape(-1,x_mean.shape[0]) - x_mean) / (x_std+1e-9)\n",
    "    inputs_[np.isnan(inputs_)] = 0\n",
    "    pre = model.predict(inputs_)\n",
    "    pred = pre * (1e-9+y_std) + y_mean\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d360bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Tp_brgr_svr.pkl', 'rb') as f:\n",
    "    regr = pickle.load(f)\n",
    "    \n",
    "calc = Calculator(descriptors, ignore_3D=True)\n",
    "PN_descriptors_mord = {}\n",
    "for i, desc in enumerate(calc.descriptors):\n",
    "    if desc.__str__() in regr.PN_xnames:\n",
    "        PN_descriptors_mord[desc.__str__()] = desc\n",
    "ini_descriptors_mord = {}\n",
    "for i, desc in enumerate(calc.descriptors):\n",
    "    if desc.__str__() in regr.ini_xnames:\n",
    "        ini_descriptors_mord[desc.__str__()] = desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dcc635",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(regr.ini_dict):\n",
    "    PN_smiles_list = 'C[Si](c1cc(Oc2cc(C#N)c(C#N)cc2)ccc1)(c3cc(Oc4cc(C#N)c(C#N)cc4)ccc3)c5ccccc5'\n",
    "    result = tp_pre(regr, get_input(PN_smiles_list, regr.ini_dict[key], 10, PN_descriptors_mord, ini_descriptors_mord))\n",
    "    print(key, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f30667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
